{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1bTVBv4eEy3_X6ZN9jrIq6ldi4HI6pUHa","timestamp":1677691099019},{"file_id":"1RTNSumd-g27D8N6w9ivhoTKsHeazlRrW","timestamp":1677678589981}],"authorship_tag":"ABX9TyMxO1RdiZCADuwgblqJz3bo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["\n","\n","# Vector Space Model"],"metadata":{"id":"_xUxJNEVY8QH"}},{"cell_type":"markdown","source":["This notebook uses the VSM Cosine Similarity ranking formula for information retrieval of documents based on a query search. \n","\n","The documents, from a fixed repository, are scored and ranked for similarity against a test set of queries. The output results are used for evaluation using the trec_eval tool.\n","\n","In the final section, the notebook allows a user to manually enter a free form text search to test this against the existing documents repository, using the same ranking model - useful for exploratory testing."],"metadata":{"id":"3c68PcxEq5xV"}},{"cell_type":"markdown","source":["## Imports and setup"],"metadata":{"id":"YwmxO2WVV3dk"}},{"cell_type":"code","source":["import math\n","import numpy as np\n","import pandas as pd\n","import csv\n","import os\n","import nltk\n","from nltk.corpus import reuters\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","from nltk.text import log\n","import xml.etree.ElementTree as ET\n","\n","nltk.download('reuters')\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","\n","stop_words = set(stopwords.words(\"english\"))"],"metadata":{"id":"83vPqtruu3tj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678975431082,"user_tz":0,"elapsed":4625,"user":{"displayName":"Anthony Forde","userId":"14193265044366032824"}},"outputId":"4b46d123-dddd-4bfd-a406-5c8d1534fd43"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package reuters to /root/nltk_data...\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]}]},{"cell_type":"code","source":["# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"LQxhV4KOglC3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678975846087,"user_tz":0,"elapsed":81411,"user":{"displayName":"Anthony Forde","userId":"14193265044366032824"}},"outputId":"56579b7d-ef93-4c50-b9d9-4917397f3859"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["## Part 1 - Ranking by document titles\n","In this section we score each search query for document title and create a shortlist of the top 100 relevant documents (by title)."],"metadata":{"id":"HllRjccnSp7l"}},{"cell_type":"markdown","source":["### Setup"],"metadata":{"id":"8R53l2_r6eeM"}},{"cell_type":"code","source":["# Create base dataframe for recording results\n","df_Results = pd.DataFrame(columns=['Query_ID','Doc_ID', 'VSM_Score','Query_Desc', 'Doc_Desc'])"],"metadata":{"id":"yFdEWJltdKxl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_Results.drop(df_Results.index,inplace=True)"],"metadata":{"id":"lvcA9Yuui0fb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Bring in the data"],"metadata":{"id":"qGAvL3AuWFHp"}},{"cell_type":"markdown","source":["Indexed queries and documents preprepared from previous notebook"],"metadata":{"id":"4UaeZUBRWTD9"}},{"cell_type":"code","source":["os.chdir(\"/content/drive/MyDrive/CA6005I - Mechanics of Search/Assignment1/Files_Indexed\")"],"metadata":{"id":"JLwBfx_rg_PQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Document titles file"],"metadata":{"id":"x_WU48v2Wm-v"}},{"cell_type":"code","source":["# Import from prepared CSV file - read doc IDs and titles to array\n","with open('Indexed_Titles.csv', 'r') as file:\n","    reader = csv.reader(file)\n","    documents = []\n","    documentIDs = []\n","    for row in reader:\n","        documentIDs.append(row[1])\n","        documents.append(row[2])"],"metadata":{"id":"ZHclyUE0gk47"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Search queries file"],"metadata":{"id":"sAM1IURxZjfc"}},{"cell_type":"code","source":["# Import from prepared CSV file - read query IDs and search strings to array\n","with open('Indexed_Queries.csv', 'r') as file:\n","    reader = csv.reader(file)\n","    queries = []\n","    queryIDs = []\n","    for row in reader:\n","        queries.append(row[2])\n","        queryIDs.append((row[1]))"],"metadata":{"id":"32PpkQbDZgmb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Vectorisation"],"metadata":{"id":"lRe2IjYEXpQp"}},{"cell_type":"markdown","source":["Preprocessing and stopwords removal"],"metadata":{"id":"CLuamG9dWzur"}},{"cell_type":"code","source":["# Split document titles into individual words and remove stop words\n","def preprocess(documents):\n","    #stop_words = [\"the\", \"a\", \"an\", \"and\", \"or\", \"in\", \"on\", \"at\", \"is\"]\n","    preprocessed_docs = []\n","    for doc in documents:\n","        words = doc.lower().split()\n","        words = [word for word in words if word not in stop_words]\n","        preprocessed_docs.append(words)\n","    return preprocessed_docs"],"metadata":{"id":"t8Tt-0smrBKU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["preprocessed_docs = preprocess(documents)"],"metadata":{"id":"nKmMdCJIrBL_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create vocabulary from the documents\n","vocab = sorted(set(word for doc in preprocessed_docs for word in doc))"],"metadata":{"id":"LAXk---qrBP9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Vectorisation"],"metadata":{"id":"Skp4J7EQXiVI"}},{"cell_type":"code","source":["# Convert title document into a vector representation using the vocabulary\n","def vectorize(doc, vocab):\n","    vector = np.zeros(len(vocab))\n","    for word in doc:\n","        if word in vocab:\n","            vector[vocab.index(word)] += 1\n","    return vector"],"metadata":{"id":"FZL_PIuvrBRy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Vectorize preprocessed documents\n","vectors = [vectorize(doc, vocab) for doc in preprocessed_docs]"],"metadata":{"id":"mTfKUivDrBV5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Similarity"],"metadata":{"id":"6Pmn9bgvYNZo"}},{"cell_type":"markdown","source":["Compute cosine similarity between two vectors"],"metadata":{"id":"PiUvbwqSYXFZ"}},{"cell_type":"code","source":["def cosine_similarity(u, v):\n","    score = np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v))\n","    if np.isnan(score):\n","      # To cater for values so close to zero they are being treated as NAN\n","      score = 0\n","    return score"],"metadata":{"id":"jrkOaJTorBXv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Process queries"],"metadata":{"id":"BteNFlyZYnPU"}},{"cell_type":"markdown","source":["For each query, a similarity score is computed for every document"],"metadata":{"id":"WFn99Yg9Z3-H"}},{"cell_type":"code","source":["current_query = 0\n","# For each query\n","for item in queries:\n","\n","  rawquery = queries[current_query]\n","  query = queries[current_query]\n","  queryID = queryIDs[current_query]\n","  query = query.split()\n","\n","  for i in range(len(query)):\n","      query[i] = query[i].lower()\n","  query = [string for string in query if string not in stop_words]  \n","  \n","  query_vec = vectorize(query, vocab)\n","\n","  # Compute cosine similarity for all documents (previously vectorised above)\n","  similarities = [cosine_similarity(query_vec, vector) for vector in vectors]\n","\n","  current_score = 0\n","  # For each computed similarity score\n","  for score in similarities:\n","    # Append a new row to the results dataframe\n","    new_row = [int(queryID), int(documentIDs[current_score]), score, rawquery, documents[current_score]]\n","    df_Results = df_Results.append(pd.Series(new_row, index=df_Results.columns), ignore_index=True)\n","    current_score += 1\n","  \n","  current_query += 1"],"metadata":{"id":"4gSB7RkP-XJC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Sort the results: group by query ID, then sorted by scores ascending for each query. Finally, optionally, retain only top results for each query search, e.g. 10, 50, 100..."],"metadata":{"id":"jYrQT8ifaYr9"}},{"cell_type":"code","source":["df_SortedResults = df_Results.sort_values(by=['Query_ID', 'Cosine_Score'], ascending=[True, False])"],"metadata":{"id":"KwaW3EJgHfo8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Restrict to top 100 results\n","df_TopResults = df_SortedResults.groupby('Query_ID').head(100).reset_index(drop=True)"],"metadata":{"id":"JZik2E8BHfr5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_TopResults.insert(4, 'Rank',0)"],"metadata":{"id":"L8QIPCDXjSdv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_TopResults['Rank'] = df_TopResults.groupby('Query_ID').cumcount() + 1"],"metadata":{"id":"2DQ5qqOBlN1b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Export final results to CSV for final analysis (outside of this notebook)\n","df_TopResults.to_csv(\"Export_VSM_Top100_by_Title.csv\")"],"metadata":{"id":"r7DnBf_WFiy0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Part 2 - Ranking by document contents\n","In this section we score each search query for document contents (main body of the document) and create a shortlist of the top 100 relevant documents (by contents)."],"metadata":{"id":"L75F7jh9StVt"}},{"cell_type":"markdown","source":["### Setup"],"metadata":{"id":"L3G6iCSsStVt"}},{"cell_type":"code","source":["# Create base dataframe for recording results\n","df_Results = pd.DataFrame(columns=['Query_ID','Doc_ID', 'Cosine_Score'])"],"metadata":{"id":"dGWSeLxfStVu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_Results.drop(df_Results.index,inplace=True)"],"metadata":{"id":"BYxf3eGlStVu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Bring in the data"],"metadata":{"id":"G4NZIND4StVu"}},{"cell_type":"markdown","source":["Indexed queries and documents preprepared from previous notebook"],"metadata":{"id":"adRKDBbQStVv"}},{"cell_type":"code","source":["os.chdir(\"/content/drive/MyDrive/CA6005I - Mechanics of Search/Assignment1/Files_Indexed\")"],"metadata":{"id":"xxSaZApJStVv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Document titles file"],"metadata":{"id":"5GQ30t7TStVv"}},{"cell_type":"code","source":["# Import from prepared CSV file - read doc IDs and titles to array\n","with open('Indexed_Contents.csv', 'r') as file:\n","    reader = csv.reader(file)\n","    documents = []\n","    documentIDs = []\n","    for row in reader:\n","        documentIDs.append(row[1])\n","        documents.append(row[2])"],"metadata":{"id":"vObFeoSaStVw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Search queries file"],"metadata":{"id":"nB6MKJDpStVw"}},{"cell_type":"code","source":["# Import from prepared CSV file - read query IDs and search strings to array\n","with open('Indexed_Queries', 'r') as file:\n","    reader = csv.reader(file)\n","    queries = []\n","    queryIDs = []\n","    for row in reader:\n","        queries.append(row[2])\n","        queryIDs.append((row[1]))"],"metadata":{"id":"RokvLXuiStVw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Vectorisation"],"metadata":{"id":"eynUDczTStVw"}},{"cell_type":"markdown","source":["Preprocessing and stopwords removal"],"metadata":{"id":"MMQ3HxGZStVx"}},{"cell_type":"code","source":["# Split document titles into individual words and remove stop words\n","def preprocess(documents):\n","    #stop_words = [\"the\", \"a\", \"an\", \"and\", \"or\", \"in\", \"on\", \"at\", \"is\"]\n","    preprocessed_docs = []\n","    for doc in documents:\n","        words = doc.lower().split()\n","        words = [word for word in words if word not in stop_words]\n","        preprocessed_docs.append(words)\n","    return preprocessed_docs"],"metadata":{"id":"afM5IyA_StVx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["preprocessed_docs = preprocess(documents)"],"metadata":{"id":"uQ7Rc8jAStVx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create vocabulary from the documents\n","vocab = sorted(set(word for doc in preprocessed_docs for word in doc))"],"metadata":{"id":"fZdspbk5StVy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Vectorisation"],"metadata":{"id":"UA7D5ry4StVy"}},{"cell_type":"code","source":["# Convert title document into a vector representation using the vocabulary\n","def vectorize(doc, vocab):\n","    vector = np.zeros(len(vocab))\n","    for word in doc:\n","        if word in vocab:\n","            vector[vocab.index(word)] += 1\n","    return vector"],"metadata":{"id":"uulksT_oStVz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Vectorize preprocessed documents\n","vectors = [vectorize(doc, vocab) for doc in preprocessed_docs]"],"metadata":{"id":"ADnPuVDwStVz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Similarity"],"metadata":{"id":"BYdb17Q4StV0"}},{"cell_type":"markdown","source":["Compute cosine similarity between two vectors"],"metadata":{"id":"1UIA2u7cStV0"}},{"cell_type":"code","source":["def cosine_similarity(u, v):\n","    score = np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v))\n","    if np.isnan(score):\n","      # To cater for values so close to zero they are being treated as NAN\n","      score = 0\n","    return score"],"metadata":{"id":"dR1C1JBVStV0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Process queries"],"metadata":{"id":"5okfL8sVStV1"}},{"cell_type":"markdown","source":["For each query, a similarity score is computed for every document"],"metadata":{"id":"SXgGwEIZStV1"}},{"cell_type":"code","source":["current_query = 0\n","# For each query\n","for item in queries:\n","\n","  rawquery = queries[current_query]\n","  query = queries[current_query]\n","  queryID = queryIDs[current_query]\n","  query = query.split()\n","\n","  for i in range(len(query)):\n","      query[i] = query[i].lower()\n","  query = [string for string in query if string not in stop_words]  \n","  \n","  query_vec = vectorize(query, vocab)\n","\n","  # Compute cosine similarity for all documents (previously vectorised above)\n","  similarities = [cosine_similarity(query_vec, vector) for vector in vectors]\n","\n","  current_score = 0\n","  # For each computed similarity score\n","  for score in similarities:\n","    # Append a new row to the results dataframe\n","    new_row = [int(queryID), int(documentIDs[current_score]), score]\n","    df_Results = df_Results.append(pd.Series(new_row, index=df_Results.columns), ignore_index=True)\n","    current_score += 1\n","  \n","  current_query += 1"],"metadata":{"id":"6HASBsYjStV1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Sort the results: group by query ID, then sorted by scores ascending for each query. Finally, optionally, retain only top results for each query search, e.g. 10, 50, 100..."],"metadata":{"id":"zB71W_wxStV2"}},{"cell_type":"code","source":["df_SortedResults = df_Results.sort_values(by=['Query_ID', 'Cosine_Score'], ascending=[True, False])"],"metadata":{"id":"w8ZrpehgStV2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Restrict to top 100 results\n","df_TopResults = df_SortedResults.groupby('Query_ID').head(100).reset_index(drop=True)"],"metadata":{"id":"tthBZDZFStV2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_TopResults['Rank'] = df_TopResults.groupby('Query_ID').cumcount() + 1"],"metadata":{"id":"dUkogsVKStV3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_TopResults.to_csv(\"Export_VSM_Top100_by_Content.csv\")"],"metadata":{"id":"POU5dfecStV4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Part 3 - Test a single query\n","\n","Enter a freeform query search against the documents repository"],"metadata":{"id":"hOeqWOs-unVk"}},{"cell_type":"markdown","source":["### Setup"],"metadata":{"id":"KE65DPTaunVs"}},{"cell_type":"markdown","source":["Read indexed document titles data into dataframe - title to be used in search results summary\n"],"metadata":{"id":"8GxDLs6JBxrn"}},{"cell_type":"code","source":["os.chdir(\"/content/drive/MyDrive/CA6005I - Mechanics of Search/Assignment1/Files_Indexed\")\n","df_titles = []\n","df_titles = pd.DataFrame(columns=['Index','Doc_ID', 'Title'])\n","title_data = pd.read_csv(\"Indexed_Titles.csv\", names=['Index','Doc_ID', 'Title'])\n","df_titles = df_titles.append(title_data, ignore_index=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7PIkssK06Gim","executionInfo":{"status":"ok","timestamp":1678980418427,"user_tz":0,"elapsed":6,"user":{"displayName":"Anthony Forde","userId":"14193265044366032824"}},"outputId":"27255f64-b082-427c-f20a-8d32c431cf09"},"execution_count":75,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-75-c9fbfc68a0e5>:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  df_titles = df_titles.append(title_data, ignore_index=True)\n"]}]},{"cell_type":"markdown","source":["Create base dataframe for recording results\n"],"metadata":{"id":"4PAfITjmB35c"}},{"cell_type":"code","source":["df_Results =[]\n","df_Results = pd.DataFrame(columns=['Query_ID','Doc_ID', 'Cosine_Score', 'Rank', 'Title'])\n","df_Results.drop(df_Results.index,inplace=True)"],"metadata":{"id":"J5X4Iu_AunVt","executionInfo":{"status":"ok","timestamp":1678980479713,"user_tz":0,"elapsed":207,"user":{"displayName":"Anthony Forde","userId":"14193265044366032824"}}},"execution_count":77,"outputs":[]},{"cell_type":"markdown","source":["### Bring in the data"],"metadata":{"id":"0Zn01ztdunVt"}},{"cell_type":"markdown","source":["Indexed queries and documents preprepared from previous notebook"],"metadata":{"id":"XlIwTmLlunVt"}},{"cell_type":"markdown","source":["Document Contents file"],"metadata":{"id":"0utL2OpaunVu"}},{"cell_type":"code","source":["os.chdir(\"/content/drive/MyDrive/CA6005I - Mechanics of Search/Assignment1/Files_Indexed\")\n","\n","# Import from prepared CSV file - read doc IDs and titles to array\n","with open('Indexed_Contents.csv', 'r') as file:\n","    reader = csv.reader(file)\n","    documents = []\n","    documentIDs = []\n","    for row in reader:\n","        documentIDs.append(row[1])\n","        documents.append(row[2])"],"metadata":{"id":"wEP4R6UKunVu","executionInfo":{"status":"ok","timestamp":1678980488381,"user_tz":0,"elapsed":237,"user":{"displayName":"Anthony Forde","userId":"14193265044366032824"}}},"execution_count":78,"outputs":[]},{"cell_type":"markdown","source":["### Vectorisation"],"metadata":{"id":"6_Ql3meZunVv"}},{"cell_type":"markdown","source":["Preprocessing and stopwords removal"],"metadata":{"id":"NdBxH35dunVv"}},{"cell_type":"code","source":["# Split document titles into individual words and remove stop words\n","def preprocess(documents):\n","    preprocessed_docs = []\n","    for doc in documents:\n","        words = doc.lower().split()\n","        words = [word for word in words if word not in stop_words]\n","        preprocessed_docs.append(words)\n","    return preprocessed_docs"],"metadata":{"id":"uwIc_fnVunVv","executionInfo":{"status":"ok","timestamp":1678980492297,"user_tz":0,"elapsed":219,"user":{"displayName":"Anthony Forde","userId":"14193265044366032824"}}},"execution_count":79,"outputs":[]},{"cell_type":"code","source":["preprocessed_docs = preprocess(documents)"],"metadata":{"id":"99GZFvRaunVv","executionInfo":{"status":"ok","timestamp":1678980494373,"user_tz":0,"elapsed":5,"user":{"displayName":"Anthony Forde","userId":"14193265044366032824"}}},"execution_count":80,"outputs":[]},{"cell_type":"code","source":["# Create vocabulary from the documents\n","vocab = sorted(set(word for doc in preprocessed_docs for word in doc))"],"metadata":{"id":"Em83sIOuunVw","executionInfo":{"status":"ok","timestamp":1678979421821,"user_tz":0,"elapsed":2,"user":{"displayName":"Anthony Forde","userId":"14193265044366032824"}}},"execution_count":65,"outputs":[]},{"cell_type":"markdown","source":["Vectorisation"],"metadata":{"id":"TiYo2g14unVw"}},{"cell_type":"code","source":["# Convert title document into a vector representation using the vocabulary\n","def vectorize(doc, vocab):\n","    vector = np.zeros(len(vocab))\n","    for word in doc:\n","        if word in vocab:\n","            vector[vocab.index(word)] += 1\n","    return vector"],"metadata":{"id":"CDqEhufdunVw","executionInfo":{"status":"ok","timestamp":1678980500835,"user_tz":0,"elapsed":214,"user":{"displayName":"Anthony Forde","userId":"14193265044366032824"}}},"execution_count":81,"outputs":[]},{"cell_type":"code","source":["# Vectorize preprocessed documents\n","vectors = [vectorize(doc, vocab) for doc in preprocessed_docs]"],"metadata":{"id":"j9e0VVgxunVx","executionInfo":{"status":"ok","timestamp":1678980548126,"user_tz":0,"elapsed":45370,"user":{"displayName":"Anthony Forde","userId":"14193265044366032824"}}},"execution_count":82,"outputs":[]},{"cell_type":"markdown","source":["### Similarity"],"metadata":{"id":"1Ms430K_unVx"}},{"cell_type":"markdown","source":["Compute cosine similarity between two vectors"],"metadata":{"id":"SS-Rb59HunVx"}},{"cell_type":"code","source":["def cosine_similarity(u, v):\n","    score = np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v))\n","    if np.isnan(score):\n","      # To cater for values so close to zero they are being treated as NAN\n","      score = 0\n","    return score"],"metadata":{"id":"liuf4bkmunVx","executionInfo":{"status":"ok","timestamp":1678980550725,"user_tz":0,"elapsed":204,"user":{"displayName":"Anthony Forde","userId":"14193265044366032824"}}},"execution_count":83,"outputs":[]},{"cell_type":"markdown","source":["### Process queries\n","- Type a query ==> similarity score is computed for every document.\n","\n","- Results display top 10 ranked documents and a title summary for each.\n","\n","- Open a document file using the listed document ID."],"metadata":{"id":"wQOZJ65MunVx"}},{"cell_type":"markdown","source":["Enter query"],"metadata":{"id":"aTeT3uGxunVy"}},{"cell_type":"code","source":["# query = 'what blah blah laws must be OBEYED when constructing aeroelastic models of heated high speed aircraft'\n","# query = 'fly me to the moon in a high speed turbo jet'\n","# query = 'experimental model techniques and equipment'\n","query = 'similarity laws for stressing heated wings'\n","\n","df_Results.drop(df_Results.index,inplace=True)\n","processed_query = rawquery.split()\n","\n","for i in range(len(processed_query)):\n","    processed_query[i] = processed_query[i].lower()\n","processed_query = [string for string in processed_query if string not in stop_words]  \n","\n","query_vec = vectorize(processed_query, vocab)\n","\n","# Compute cosine similarity for all documents (previously vectorised above)\n","similarities = [cosine_similarity(query_vec, vector) for vector in vectors]\n","\n","current_score = 0\n","# For each computed similarity score\n","for score in similarities:\n","  # Append a new row to the results dataframe\n","  new_row = [\"USER\", int(documentIDs[current_score]), score, 0, \"\"]\n","  df_Results = df_Results.append(pd.Series(new_row, index=df_Results.columns), ignore_index=True)\n","  current_score += 1"],"metadata":{"id":"Neuu1U2gunVy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Sort the results: group by query ID, then sorted by scores ascending for each query. Finally, optionally, retain only top results for each query search, e.g. 10, 50, 100..."],"metadata":{"id":"KDCtDXYYunVy"}},{"cell_type":"code","source":["df_SortedResults = []\n","df_TopResults = []\n","df_SortedResults = df_Results.sort_values(by=['Query_ID', 'Cosine_Score'], ascending=[True, False])\n","# Restrict to top 10 results\n","df_TopResults = df_SortedResults.groupby('Query_ID').head(10).reset_index(drop=True)\n","df_TopResults['Rank'] = df_TopResults.groupby('Query_ID').cumcount() + 1\n","\n","for index, row in df_titles.iterrows():\n","  df_TopResults.loc[(df_TopResults.Doc_ID == row['Doc_ID']), 'Title'] = row['Title']\n","\n","\n","print(\"--- QUERY: \" + query + \"\\n\")\n","df_TopResults"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":397},"id":"u1Zr-0tC0pNv","executionInfo":{"status":"ok","timestamp":1678981000601,"user_tz":0,"elapsed":542,"user":{"displayName":"Anthony Forde","userId":"14193265044366032824"}},"outputId":"cdac6bc8-fb88-43a7-e5b0-ced59bbb072b"},"execution_count":94,"outputs":[{"output_type":"stream","name":"stdout","text":["--- QUERY: similarity laws for stressing heated wings\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["  Query_ID Doc_ID  Cosine_Score  Rank  \\\n","0     USER    429      0.228665     1   \n","1     USER    878      0.218218     2   \n","2     USER     12      0.204124     3   \n","3     USER     51      0.200643     4   \n","4     USER   1144      0.172363     5   \n","5     USER    792      0.167718     6   \n","6     USER    747      0.161881     7   \n","7     USER     13      0.147893     8   \n","8     USER    746      0.144620     9   \n","9     USER    253      0.141365    10   \n","\n","                                               Title  \n","0  a description of the r. a. e.  high speed supe...  \n","1  experimental model techniques and equipment fo...  \n","2  some structural and aerelastic considerations ...  \n","3  theory of aircraft structural models subjected...  \n","4  slipstream flow around several tilt-wing vtol ...  \n","5     some low speed problems of high speed aircraft  \n","6  bodt freedom flutter of ground launched rocket...  \n","7         similarity laws for stressing heated wings  \n","8  aeroelastic problems in connection with high s...  \n","9  on the ground level disturbance from large air...  "],"text/html":["\n","  <div id=\"df-62194bb1-fa1d-4662-afd0-7e512ba649a1\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Query_ID</th>\n","      <th>Doc_ID</th>\n","      <th>Cosine_Score</th>\n","      <th>Rank</th>\n","      <th>Title</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>USER</td>\n","      <td>429</td>\n","      <td>0.228665</td>\n","      <td>1</td>\n","      <td>a description of the r. a. e.  high speed supe...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>USER</td>\n","      <td>878</td>\n","      <td>0.218218</td>\n","      <td>2</td>\n","      <td>experimental model techniques and equipment fo...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>USER</td>\n","      <td>12</td>\n","      <td>0.204124</td>\n","      <td>3</td>\n","      <td>some structural and aerelastic considerations ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>USER</td>\n","      <td>51</td>\n","      <td>0.200643</td>\n","      <td>4</td>\n","      <td>theory of aircraft structural models subjected...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>USER</td>\n","      <td>1144</td>\n","      <td>0.172363</td>\n","      <td>5</td>\n","      <td>slipstream flow around several tilt-wing vtol ...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>USER</td>\n","      <td>792</td>\n","      <td>0.167718</td>\n","      <td>6</td>\n","      <td>some low speed problems of high speed aircraft</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>USER</td>\n","      <td>747</td>\n","      <td>0.161881</td>\n","      <td>7</td>\n","      <td>bodt freedom flutter of ground launched rocket...</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>USER</td>\n","      <td>13</td>\n","      <td>0.147893</td>\n","      <td>8</td>\n","      <td>similarity laws for stressing heated wings</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>USER</td>\n","      <td>746</td>\n","      <td>0.144620</td>\n","      <td>9</td>\n","      <td>aeroelastic problems in connection with high s...</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>USER</td>\n","      <td>253</td>\n","      <td>0.141365</td>\n","      <td>10</td>\n","      <td>on the ground level disturbance from large air...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-62194bb1-fa1d-4662-afd0-7e512ba649a1')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-62194bb1-fa1d-4662-afd0-7e512ba649a1 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-62194bb1-fa1d-4662-afd0-7e512ba649a1');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":94}]},{"cell_type":"code","source":["intdocno = 429\n","\n","os.chdir(\"/content/drive/MyDrive/CA6005I - Mechanics of Search/Assignment1/Files_Individual_Docs\")\n","xml_file = \"document_\" + str(intdocno) + \".xml\"\n","\n","# parse the XML file\n","tree = ET.parse(xml_file)\n","\n","# get the root element of the XML file\n","root = tree.getroot()\n","\n","print(\"--- QUERY: \" + query + \"\\n\")\n","print(\"--- DOCUMENT: \" + \"\\n\")\n","\n","# print the contents of the XML file\n","for child in root:\n","    print(ET.tostring(child, encoding='unicode'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678981019792,"user_tz":0,"elapsed":197,"user":{"displayName":"Anthony Forde","userId":"14193265044366032824"}},"outputId":"6fe0268d-0f6a-44d1-fa12-f65f462c04d7","id":"LXKdn8fv1uKJ"},"execution_count":95,"outputs":[{"output_type":"stream","name":"stdout","text":["--- QUERY: similarity laws for stressing heated wings\n","\n","--- DOCUMENT: \n","\n","<docno>429</docno>\n","\n","<title>a description of the r. a. e.  high speed supersonic\n","tunnel .</title>\n","\n","<author>poole,j.a.</author>\n","\n","<bib>rae tn.aero.2678,1960</bib>\n","\n","<text>a description of the r. a. e.  high speed supersonic\n","tunnel .\n","  an account is given of the high supersonic speed tunnel now nearing\n","completion .  the design philosophy is reviewed, the principal features\n","are described and some of the more interesting development problems\n","are noted .</text>\n"]}]}]}