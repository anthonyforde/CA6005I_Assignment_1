{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPfxl2Sx9ByH/OU6bOaNozy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Read and index Cran files"],"metadata":{"id":"aWYZWyc21CDD"}},{"cell_type":"markdown","source":["### This notebook reads in the Cran raw data and prepares the document and query files for processing. It is a one off process, the output files of which are used for indexing and ranking in subsequent notebooks for different IR models.\n","\n","STEPS:\n","\n","##### 1. Read Cran documents raw data - \"**cran.all.1400.xml**\": This is the XML file containing all sample documents. \n","##### 2. Split this file (of all documents) into indivdual XML files, one for each document, and save to a new folder.\n","##### 3. Retrieve all document titles, indexed by document number and save to CSV file (to be used for subsequent query/document indexation and ranking).\n","##### 4. Retrieve all document contens (main doc body), indexed by document number and save to CSV file (to be used for subsequent query/document indexation and ranking).\n","##### 5. Read Cran queries raw data - \"**cran.qry.xml**\": This is the XML file containing all sample queries. \n","##### 6. Split this file (of all queries) into indivdual XML files, one for each query, and save to a new folder.\n","##### 7. Retrieve all query titles, indexed by document number and save to CSV file (to be used for subsequent query/document indexation and ranking)."],"metadata":{"id":"hcNWxfUWzgtn"}},{"cell_type":"markdown","source":["### Imports and setup"],"metadata":{"id":"aOEXPsG81B5l"}},{"cell_type":"code","source":["import csv\n","import xml.etree.ElementTree as ET"],"metadata":{"id":"Mk8TnOdNGvln"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"51sgTb88K41o","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678188061098,"user_tz":0,"elapsed":20797,"user":{"displayName":"Anthony Forde","userId":"14193265044366032824"}},"outputId":"51db4fce-e484-457a-fc43-2ca10f728a0d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import os"]},{"cell_type":"markdown","source":["### Documents processing"],"metadata":{"id":"kmWAoFQY1dmO"}},{"cell_type":"markdown","source":["##### Split master document XML file into individual document XML files"],"metadata":{"id":"wP2BnESM75dS"}},{"cell_type":"code","source":["os.chdir(\"/content/drive/MyDrive/CA6005I - Mechanics of Search/Assignment1/Files_Cran_Original\")"],"metadata":{"id":"Ckr_B0pm2OYk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Set the path to the input file\n","input_file = \"cran.all.1400.xml\"\n","\n","# Set the XML tag to split the file into individual doc's\n","split_tag = \"</doc>\"\n","\n","# Read input file into memory\n","with open(input_file, \"r\") as f:\n","    data = f.read()"],"metadata":{"id":"ImLwAKF5svP_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Split the data into separate XML documents based on split tag\n","documents = data.split(split_tag)\n","\n","# Remove whitespaces from each document\n","documents = [doc.strip() for doc in documents]"],"metadata":{"id":"reRRHm_5w1Az"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Folder for output individual documents\n","output_dir = \"Files_Individual_Docs\"\n","\n","os.chdir(\"/content/drive/MyDrive/CA6005I - Mechanics of Search/Assignment1/\")"],"metadata":{"id":"jFTwPq9Lw1Cy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Write each document to a separate file\n","for i, doc in enumerate(documents):\n","    # Create a filename for the output file\n","    output_filename = os.path.join(output_dir, f\"document_{i+1}.xml\")\n","    # Write the document to the output file\n","    with open(output_filename, \"w\") as f:\n","        f.write(doc + split_tag)"],"metadata":{"id":"R-ZRTc6Fw1Ge"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Retrieve all document titles and read to single CSV file indexed by document number: \"**Indexed_Titles.csv**\""],"metadata":{"id":"Nmi5Bmjh7_6c"}},{"cell_type":"code","source":["os.chdir(\"/content/drive/MyDrive/CA6005I - Mechanics of Search/Assignment1/Files_Individual_Docs\")\n","!ls"],"metadata":{"id":"CsWpiRgS8Uhq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["array_titles = []\n","i = 0\n","\n","for filename in os.listdir():\n","\n","  print(\"Processing file... \" + str(i+1))  \n","  tree = ET.parse(filename)\n","  root = tree.getroot()\n","\n","  # Get title and doc number\n","  docno = root.find('docno').text\n","  title = root.find('title').text\n","\n","  #print(\"Got doc num... \" + str(docno))    \n","\n","  if title is None:\n","    title = \"**NODATA**\"\n","    #print(\"Found no data for doc no: \" + str(docno))\n","\n","  # Remove end of line characters and end of sentence periods from titles\n","  title = title.replace(\"\\n\", \" \")\n","  title = title.replace(\" .\", \"\")  \n","\n","  array_titles.append([i, docno, title])\n","  i += 1"],"metadata":{"id":"OC3x2F_08p3P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in array_titles:\n","  print(i)"],"metadata":{"id":"JEWxbqo98p6-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["os.chdir(\"/content/drive/MyDrive/CA6005I - Mechanics of Search/Assignment1/Files_Indexed\")\n","\n","titles_csv_file = \"Indexed_Titles.csv\"\n","\n","# Open the output CSV file for writing\n","with open(titles_csv_file, \"w\", newline=\"\") as csv_file:\n","    csv_writer = csv.writer(csv_file)\n","    csv_writer.writerows(array_titles)"],"metadata":{"id":"ZoKSn3sZ8p9v"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Retrieve all document contents and read to single CSV file indexed by document number: \"**Indexed_Contents.csv**\""],"metadata":{"id":"u6IL969aGqnR"}},{"cell_type":"code","source":["os.chdir(\"/content/drive/MyDrive/CA6005I - Mechanics of Search/Assignment1/Files_Individual_Docs\")\n","!ls"],"metadata":{"id":"CwX30TKqLyx8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["array_content = []\n","i = 0\n","\n","for filename in os.listdir():\n","\n","  #print(\"Processing file... \" + str(i+1))  \n","  #print(\"Processing content... \" + filename)\n","  tree = ET.parse(filename)\n","  root = tree.getroot()\n","\n","  # Get content and doc number\n","  docno = root.find('docno').text\n","  content = root.find('text').text\n","\n","  #print(\"Got doc num... \" + str(docno))    \n","\n","  if content is None:\n","    content = \"**NODATA**\"\n","    #print(\"Found no data for doc no: \" + str(docno))\n","\n","  # Remove end of line characters and end of sentence periods from contents\n","  content = content.replace(\"\\n\", \" \")\n","  content = content.replace(\" .\", \"\")  \n","  \n","  array_content.append([i, docno, content])\n","\n","  i += 1"],"metadata":{"id":"iZ2f1cRcGl29"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["os.chdir(\"/content/drive/MyDrive/CA6005I - Mechanics of Search/Assignment1/Files_Indexed\")\n","\n","contents_csv_file = \"Indexed_Contents.csv\"\n","\n","# Open the output CSV file for writing\n","with open(contents_csv_file, \"w\", newline=\"\") as csv_file:\n","    csv_writer = csv.writer(csv_file)\n","    csv_writer.writerows(array_content)"],"metadata":{"id":"USGLsGbla9j5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Queries processing"],"metadata":{"id":"Z-rniIJd2FBC"}},{"cell_type":"markdown","source":["##### Split master query XML file into individual query XML files"],"metadata":{"id":"uEJDtaMpXQjq"}},{"cell_type":"code","source":["os.chdir(\"/content/drive/MyDrive/CA6005I - Mechanics of Search/Assignment1/Files_Cran_Original\")"],"metadata":{"id":"l_7SIpad2S1M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Set the path to the input file\n","input_file = \"cran.qry.xml\"\n","\n","# Set the XML tag to split the file into individual doc's\n","split_tag = \"</top>\"\n","\n","# Read input file into memory\n","with open(input_file, \"r\") as f:\n","    data = f.read()"],"metadata":{"id":"ALYmqmeQ2FBK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Split the data into separate XML documents based on split tag\n","documents = data.split(split_tag)\n","\n","# Remove whitespaces from each document\n","documents = [doc.strip() for doc in documents]"],"metadata":{"id":"6LbMWIUb2FBL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Folder for output individual documents\n","os.chdir(\"/content/drive/MyDrive/CA6005I - Mechanics of Search/Assignment1/Files_Individual_Queries\")"],"metadata":{"id":"opiS71zc2FBL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Write each document to a separate file\n","for i, doc in enumerate(documents):\n","    # Create a filename for the output file\n","    output_filename = os.path.join(output_dir, f\"query_{i+1}.xml\")\n","    # Write the document to the output file\n","    with open(output_filename, \"w\") as f:\n","        f.write(doc + split_tag)"],"metadata":{"id":"_ghtmjEQ2FBL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Retrieve all search queries and read to single CSV file indexed by document number: \"**Indexed_Queries.csv**\""],"metadata":{"id":"xzfVnot4XYb7"}},{"cell_type":"code","source":["os.chdir(\"/content/drive/MyDrive/CA6005I - Mechanics of Search/Assignment1/Files_Individual_Queries\")"],"metadata":{"id":"_XLjt_zUXkPA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import xml.etree.ElementTree as ET"],"metadata":{"id":"kcLFnO9IXkPB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["array_titles = []\n","i = 0\n","\n","for filename in os.listdir():\n","  tree = ET.parse(filename)\n","  root = tree.getroot()\n","\n","  # Get title and doc number\n","  querynum = i+1\n","  title = root.find('title').text\n","\n","  if title is None:\n","    title = \"**NODATA**\"\n","    print(\"Found no data for doc no: \" + str(docno))\n","\n","  querynum = querynum.strip()\n","  title = title.strip()\n","\n","  # Remove end of line characters and end of sentence periods from titles\n","  title = title.replace(\"\\n\", \" \")\n","  title = title.replace(\" .\", \"\")  \n","\n","  array_titles.append([i, querynum, title])\n","  i += 1"],"metadata":{"id":"va5ShuNcz4e4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in array_titles:\n","  print(i)"],"metadata":{"id":"5oIGpdN4z4e5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["os.chdir(\"/content/drive/MyDrive/CA6005I - Mechanics of Search/Assignment1/Files_Indexed\")\n","\n","titles_csv_file = \"Indexed_Queries.csv\"\n","\n","# Open the output CSV file for writing\n","with open(titles_csv_file, \"w\", newline=\"\") as csv_file:\n","    csv_writer = csv.writer(csv_file)\n","    csv_writer.writerows(array_titles)"],"metadata":{"id":"ZLBbPvyUXkPD"},"execution_count":null,"outputs":[]}]}